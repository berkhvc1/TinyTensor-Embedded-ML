# TinyTensor: GÃ¶mÃ¼lÃ¼ Sistemler Ä°Ã§in Bellek Optimize EdilmiÅŸ TensÃ¶r KÃ¼tÃ¼phanesi

Bu proje, Arduino ve ESP32 gibi RAM kapasitesi kÄ±sÄ±tlÄ± cihazlar Ã¼zerinde Yapay Zeka (TinyML) modellerini Ã§alÄ±ÅŸtÄ±rmak iÃ§in tasarlanmÄ±ÅŸ, bellek dostu bir **TensÃ¶r** yapÄ±sÄ± uygulamasÄ±dÄ±r. 

## ğŸš€ Ã–zellikler
* **Dinamik Veri YapÄ±sÄ±**: Tek bir bellek alanÄ± Ã¼zerinden Float32, Float16 ve Int8 tiplerini destekler.
* **Union TabanlÄ± Bellek YÃ¶netimi**: AynÄ± bellek adresini farklÄ± veri tipleri arasÄ±nda paylaÅŸtÄ±rarak RAM kullanÄ±mÄ±nÄ± minimize eder.
* **Lineer Quantization (Niceleme)**: Float32 verileri %75 bellek tasarrufu saÄŸlayan Int8 formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.

## ğŸ› ï¸ Teknik Mimari

### Union ve Struct TasarÄ±mÄ±
KÃ¼tÃ¼phanenin kalbi olan `union` yapÄ±sÄ±, farklÄ± veri tiplerinin aynÄ± bellek adresini paylaÅŸmasÄ±nÄ± saÄŸlar.

Quantization (Niceleme) MantÄ±ÄŸÄ±
Quantization iÅŸlemi, yÃ¼ksek hassasiyetli float verileri tam sayÄ±lara sÄ±kÄ±ÅŸtÄ±rÄ±r.

KullanÄ±lan FormÃ¼l:

P_quantized = round(P_float / Scale)

Bu yÃ¶ntemle her bir veri noktasÄ± bellekte 4 byte yerine sadece 1 byte yer kaplar

Bellek Analizi:

Float32: Her eleman iÃ§in 4 Byte yer kaplar.

Int8: Her eleman iÃ§in 1 Byte yer kaplar.

SonuÃ§: Quantization iÅŸlemi ile bellek kullanÄ±mÄ±nda %75 oranÄ±nda tasarruf saÄŸlanmÄ±ÅŸtÄ±r.

```c
typedef union {
    float *f32;
    uint16_t *f16;
    int8_t *i8;
} DataPointer;
